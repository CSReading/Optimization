{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter4: 計画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sympy import symbols, lambdify\n",
    "from sympy.matrices import Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1\n",
    "(問) 次3.1で考えた関数について, それぞれが凸関数であるかを調べよ.\n",
    "\n",
    "(答)\n",
    "\n",
    "(i) $f(\\bm{x}) = 2x_{1}^{3} - x_{1}^{2}x_{2} + 2x_{2}^{2}$\n",
    "\n",
    "Not convex.\n",
    "Consider $\\bm{a} = [-2, 0]^{\\top}, \\bm{b} = [0, 0]^{\\top}, \\lambda = \\frac{1}{2}$, then\n",
    "$$\n",
    "\\lambda f(\\bm{a}) + (1 - \\lambda)f(\\bm{b}) = -8\n",
    "$$\n",
    "$$\n",
    "f(\\lambda \\bm{a} + (1 - \\lambda)\\bm{b}) = -2\n",
    "$$  \n",
    "\n",
    "\n",
    "(ii) $f(\\bm{x}) = (x_{1} - 3)^{2} + x_{1}x_{2} + \\frac{1}{16}x_{2}^{4} + (x_{2} - 1)^{2}$\n",
    "\n",
    "Convex.\n",
    "\n",
    "Deriving Eigen values of $\\nabla^{2} f(\\bm{x})$ by solving \n",
    "$$\\det(\\nabla^{2} f(\\bm{x}) - \\lambda I) = 0 \\Leftrightarrow \n",
    "\\lambda^{2} - \\left(\\frac{3}{2}x_{2}^{2} + 4\\right)\\lambda + \\frac{3}{2}x_{2}^{2} +3 = 0$$\n",
    "then, both eigen values are positive because of relation between roots and coefficients.\n",
    "\n",
    "\n",
    "(iii)リッジ回帰の目的関数$f(\\bm{x})=\\|A\\bm{x}-\\bm{b}\\|_{2}^{2} + \\gamma\\|\\bm{x}\\|_{2}^{2}$\n",
    "\n",
    "Convex.\n",
    "\n",
    "For all $\\bm{y} \\in \\mathbb{R}^{m}$, \n",
    "$$\\begin{aligned}\n",
    "\\bm{y}^{\\top}\\nabla^{2} f(\\bm{x})\\bm{y} &= 2\\bm{y}^{\\top}A^{\\top}A\\bm{y} + 2\\gamma\\bm{y}^{\\top} I\\bm{y} \\\\\n",
    "& = 2 (A\\bm{y})^{\\top}(A\\bm{y}) + 2\\gamma \\bm{y}^{\\top}\\bm{y} \\\\\n",
    "& \\ge 0\n",
    "\\end{aligned}$$\n",
    "\n",
    "(iv)ロジスティクス損失関数$f(\\bm{x})=\\sum_{j=1}^{n}\\log(1 + \\exp(-x_{j}))$\n",
    "\n",
    "Convex.\n",
    "\n",
    "$\\log(1 + \\exp(-x_{j}))$ is convex since the second derivative $\\frac{\\exp(x_{1})}{(1 + \\exp(x_{1}))^{2}}$ is positive. Because, $f(\\bm{x})$ is sum of convex function, it is also convex. \n",
    "\n",
    "\n",
    "(v) log-sum-exp関数$f(\\bm{x})=\\log\\left(\\sum_{j=1}^{n}\\exp(x_{j})\\right)$. この関数は混合正規分布を用いた最尤推定やロジスティック回帰に基づく多クラス分類などに現れる. また, $\\|x\\|_{\\infty}=\\max\\{|x_{1}|, \\dots, |x_{n}|\\}$を近似する関数としてしばしば用いられる.\n",
    "$$\\nabla f(\\bm{x}) = \\frac{1}{\\sum_{j=1}^{n}\\exp(x_{j})}\\left[\\begin{matrix}\n",
    "\\exp(x_{1}) \\\\ \n",
    "\\vdots \\\\\n",
    "\\exp(x_{n})\n",
    "\\end{matrix}\\right]$$\n",
    "$$\\nabla^{2} f(\\bm{x}) = \\frac{1}{(\\sum_{j=1}^{n}\\exp(x_{j}))^{2}}\\left[\\begin{matrix}\n",
    "\\exp(x_{1})(\\sum_{j=1}^{n}\\exp(x_{j})-\\exp(x_{1})) & -\\exp(x_{2})\\exp(x_{1}) & \\dots & -\\exp(x_{n})\\exp(x_{1}) \\\\ \n",
    "-\\exp(x_{1})\\exp(x_{2}) & \\ddots & \\ddots & \\vdots \\\\\n",
    "\\vdots & \\ddots & \\ddots & -\\exp(x_{n-1})\\exp(x_{n}) \\\\\n",
    "-\\exp(x_{n})\\exp(x_{1}) & \\dots & -\\exp(x_{n})\\exp(x_{n-1}) & \\exp(x_{n})(\\sum_{j=1}^{n}\\exp(x_{j})-\\exp(x_{n})) \\\\\n",
    "\\end{matrix}\\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 \n",
    "(問) 次の関数が凸関数であることを示せ. ただし, cは正の定数とする.\n",
    "\n",
    "(答)\n",
    "\n",
    "(i) ヒンジ損失関数$f(x)=\\max\\{c-x, 0\\}$\n",
    "\n",
    "Consider area $A = \\{x, y \\in \\mathbb{R}| y \\ge c-x \\}$ and $B = \\{x, y \\in \\mathbb{R}| y \\ge 0 \\}$, which are convex.\n",
    "Then, $C =  \\{x, y \\in \\mathbb{R}| y \\ge f(x)\\} = A \\cap B$ is also convex. Hence $f(x)$ is convex.\n",
    "\n",
    "(ii) 指数損失関数$f(x)=e^{-cx}$\n",
    "\n",
    "Second derivative $c^{2}e^{-cx}$ is positive for all $x$. Since $f(x)$ is convex.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 \n",
    "(問) 次の最適化問題を2次錘計画問題(4.7)の形に直せ. ただし, $\\gamma$ は正の定数とする.\n",
    "\n",
    "(答)\n",
    "(i) $\\ell_{1}$ノルム正則化付き最小2乗法(LASSO): \n",
    "$$ \\text{Minimize }\\|A\\bm{x}-\\bm{b}\\|_{2}^{2} + \\gamma\\|\\bm{x}\\|_{1}$$\n",
    "\n",
    "(ii)$\\ell_{2}$ノルム正則化付き$\\ell_{2}$ノルム回帰:\n",
    "$$ \\text{Minimize }\\|A\\bm{x}-\\bm{b}\\|_{1} + \\gamma\\|\\bm{x}\\|_{2}$$\n",
    "\n",
    "(iii)変数$\\bm{x}_{l}\\in\\mathbb{R}^{n_{l}}(l = 1, \\dots, r)$に関する最適化問題:\n",
    "$$ \\text{Minimize }\\frac{1}{2}\\left\\|\\sum_{l=1}^{r}A_{l}\\bm{x}_{l}-\\bm{b}\\right\\|_{2}^{2} + \\gamma\\sum_{l=1}^{r}\\|\\bm{x}_{l}\\|_{2}$$\n",
    "この問題を用いたデータ解析法はグループLASSOと呼ばれる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 \n",
    "(問) 次の問に答えよ.\n",
    "\n",
    "(答)\n",
    "\n",
    "(i) 関数$h(\\bm{x})=\\|\\bm{x}\\|_{2}$の近接作用素$\\mathbf{prox}_{h}$を求めよ.\n",
    "\n",
    "(ii) グループLASSOに近接勾配法を適用したときの解の更新方法を示せ.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5\n",
    "(問) 行列$A\\in \\mathbb{R}^{m\\times n}$とベクトル$\\bm{b}\\in \\mathbb{R}^{m}$が与えられたとき, 次の問に答えよ.\n",
    "\n",
    "(答)\n",
    "\n",
    "(i) $m > n$のとき, 最小2乗法における$\\|\\ell_{2}\\|$ノルムの代わりに$\\|\\ell_{1}\\|$ノルムを用いた問題\n",
    "$$ \\text{Miznimize } \\|A\\bm{x}-\\bm{b}\\|_{1} $$\n",
    "を考える. この問題は, 最小2乗法と比べて最適解がデータに含まれる外れ値の影響を受けにくい. 交互方向乗数法を適用するために,この問題を次のように書き直す.\n",
    "$\\begin{aligned}\n",
    "\\text{Minimize }& \\|\\bm{z}\\|_{1} \\\\\n",
    "\\text{subject to } &A\\bm{x}-\\bm{b}-\\bm{z}=\\bm{0}\n",
    "\\end{aligned}$\n",
    "この問題に対する交互方向乗数法の一反復が次のようにかけることを示せ:\n",
    "$\\begin{aligned}\n",
    "\\bm{x}_{k+1} & \\leftarrow (A^{\\top}A)^{-1}A(\\bm{z}_{k}-\\bm{v}_{k}-\\bm{b}),\\\\\n",
    "\\bm{z}_{k+1, j} & \\leftarrow \\text{sthr}_{1/\\rho}((A \\bm{x}_{k+1} + \\bm{v}_{k} - \\bm{b})_{j}), &j = 1,\\dots,n, \\\\\n",
    "\\bm{v}_{k+1} & \\leftarrow \\bm{v} + A\\bm{x}_{k+1} - z_{k+1} - \\bm{b}\n",
    "\\end{aligned}$\n",
    "\n",
    "ただし, $(A\\bm{x}_{k+1}+\\bm{v}_{k}-\\bm{b})_{j}$はベクトル$A\\bm{x}_{k+1}+\\bm{v}_{k}-\\bm{b}$の第j成分を表す. また, $\\text{sthr}_{1/\\rho}=\\begin{cases}\n",
    "x - \\frac{1}{\\rho} & (x\\ge \\alpha \\text{のとき}), \\\\\n",
    "0 & (|x| < \\frac{1}{\\rho} \\text{のとき}), \\\\\n",
    "x + \\frac{1}{\\rho} & (x \\le -\\frac{1}{\\rho} \\text{のとき})\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "(ii) 基底追跡の問題(2.3)に交互方向乗数法を適用するため, 次のように書き直す:\n",
    "$\\begin{aligned}\n",
    "\\text{Minimize }_{\\bm{x}:A\\bm{x}=\\bm{b}, \\bm{z}}& \\|\\bm{z}\\|_{1} \\\\\n",
    "\\text{subject to } &\\bm{x}-\\bm{z}=\\bm{0}\n",
    "\\end{aligned}$\n",
    "この問題に対する交互方向乗数法の一反復が\n",
    "$\\begin{aligned}\n",
    "\\bm{x}_{k+1} & \\leftarrow \\argmin_{\\bm{x}}\\{\\|\\bm{x} - (\\bm{z}^{k} - \\bm{v}^{k})\\|_{2}^{2} | A\\bm{x}=\\bm{b}\\},\\\\\n",
    "\\bm{z}_{k+1, j} & \\leftarrow \\text{sthr}_{1/\\rho}((A \\bm{x}_{k+1} + \\bm{v}_{k})_{j}), &j = 1,\\dots,n, \\\\\n",
    "\\bm{v}_{k+1} & \\leftarrow \\bm{v} + A\\bm{x}_{k+1} - z_{k+1}\n",
    "\\end{aligned}$\n",
    "と書けることを示せ.次に, $\\bm{x}_{k}$の更新は\n",
    "$$ \\bm{x}_{k+1} \\leftarrow [I - A^{\\top}(AA^{\\top})^{-1}A](\\bm{z}_{k} - \\bm{v}_{k}) + A^{\\top}(AA^{\\top})^{-1}\\bm{b} $$\n",
    "と書けることを示せ."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
