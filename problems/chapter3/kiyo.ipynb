{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as spopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 \n",
    "(i) $$ f(x) = 2x_1^3 - x_1^2 x_2 + 2x_2^2 $$\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = \\begin{bmatrix}\n",
    "                6x_1^2 - 2x_1x_2 \\\\\n",
    "                - x_1^2 + 4x_2\n",
    "                \\end{bmatrix}, \\ \\ \n",
    "\\nabla^2 f(x) = \\begin{bmatrix}\n",
    "12x_1 - 2x_2 & -2x_1 \\\\\n",
    "-2x_1 & 4 \n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii) $$ f(x) = (x_1 - 3)^2 + x_1x_2 + \\frac{1}{16}x_2^4 + (x_2 - 1)^2 $$\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = \\begin{bmatrix}\n",
    "                    2x_1 + x_2 - 6 \\\\\n",
    "                    \\frac{1}{4}x_2^3 + 2x_2 + x_1 - 2\n",
    "              \\end{bmatrix}, \\ \\ \n",
    "\\nabla^2 f(x) = \\begin{bmatrix}\n",
    "                    2 & 1 \\\\\n",
    "                    1 & \\frac{3}{4}x_2^2 + 2 \n",
    "                \\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) $$ f(x) = \\| Ax-b \\|_2^2 + \\gamma \\|x\\|_2^2 $$\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = 2(A'A + \\gamma I)x - 2A'b, \\ \\ \n",
    "\\nabla^2 f(x) = 2(A'A + \\gamma I)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iv) $$ \\sum_{j = 1}^n \\log(1 + \\exp(-x_j)) $$\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = \\begin{bmatrix}\n",
    "                    \\frac{-\\exp(-x_1)}{1 + \\exp(-x_1)} \\\\\n",
    "                    \\vdots \\\\\n",
    "                    \\frac{-\\exp(-x_n)}{1 + \\exp(-x_n)}\n",
    "              \\end{bmatrix}, \\ \\ \n",
    "\\nabla^2 f(x) = \\begin{bmatrix}\n",
    "                    \\frac{\\exp(-x_1)}{(1 + \\exp(-x_1))^2} &  & O \\\\\n",
    "                      & \\ddots & \\\\\n",
    "                    O &  & \\frac{\\exp(-x_n)}{(1 + \\exp(-x_n))^2}\n",
    "                \\end{bmatrix} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(v) $$ \\log\\left( \\sum_{j = 1}^n \\exp(x_j) \\right) $$\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = \\begin{bmatrix}\n",
    "                    \\frac{\\exp(x_1)}{\\sum_{j = 1}^n \\exp(x_j)} \\\\\n",
    "                    \\vdots \\\\\n",
    "                    \\frac{\\exp(x_n)}{\\sum_{j = 1}^n \\exp(x_j)}\n",
    "              \\end{bmatrix}, \\ \\ \n",
    "\\nabla^2 f(x) = (A_{ij}) = \\begin{cases}\n",
    "                              \\frac{\\exp(x_i) \\left( \\sum_{l = 1}^n \\exp(x_l) \\right)^2 - \\exp(x_i) \\exp(x_j)}{\\left( \\sum_{l = 1}^n \\exp(x_l) \\right)^2} \\ \\ \\text{if} \\ \\ i = j \\\\\n",
    "                              -\\frac{\\exp(x_i) \\exp(x_j)}{\\left( \\sum_{l = 1}^n \\exp(x_l) \\right)^2} \\ \\ \\text{if} \\ \\ i \\neq j\n",
    "                          \\end{cases} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2\n",
    "\n",
    "(3.33) は $\\min \\frac{1}{2}x'Ax - b'x$ なので、 $f(x) = \\frac{1}{2}x'Ax - b'x$ とおくと、最適条件では $\\nabla f(x) = 0$ が必要となる。\n",
    "\n",
    "$A$ の対称性より、$\\nabla f(x) = 0 \\Leftrightarrow Ax = b$\n",
    "\n",
    "今回、 $A$ は正定値なので、 $Ax = b$ を満たす $x = x^*$ が (3.33) の解となるため、 (3.32) と一致する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x0, df, alpha_gd, n):\n",
    "    x = x0.copy()\n",
    "    for i in range(1, n+1):\n",
    "        x = x - alpha_gd * df(x)\n",
    "        print(f'iteration {i}: x = {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(x0, df, d2f, alpha_nm, n):\n",
    "    x = x0.copy()\n",
    "    for i in range(1, n+1):\n",
    "        f = lambda y: d2f(x) @ y + df(x)\n",
    "        d = spopt.root(f, np.ones(len(x0)))\n",
    "        x = x + alpha_nm * d.x\n",
    "        print(f'iteration {i}: x = {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grandient descent\n",
      "iteration 1: x = [0.4   0.325]\n",
      "iteration 2: x = [0.33  0.211]\n",
      "Newton method\n",
      "iteration 1: x = [ 0.19736842 -0.01315789]\n",
      "iteration 2: x = [0.09978658 0.00010879]\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "alpha_gd = 0.1\n",
    "alpha_nm = 1.0\n",
    "x0 = np.array([0.5, 0.5])\n",
    "df = lambda x: np.array([6*(x[0]**2) - 2*x[0]*x[1], -(x[0]**2) + 4*x[1]])\n",
    "d2f = lambda x: np.array([[12*x[0] - 2*x[1], -2*x[0]], [-2*x[0], 4]])\n",
    "\n",
    "print(\"Grandient descent\")\n",
    "gradient_descent(x0, df, alpha_gd, n)\n",
    "\n",
    "print(\"Newton method\")\n",
    "newton_method(x0, df, d2f, alpha_nm, n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grandient descent\n",
      "iteration 1: x = [0.95     0.546875]\n",
      "iteration 2: x = [1.3053125  0.53841112]\n",
      "Newton method\n",
      "iteration 1: x = [ 3.27777778 -0.55555556]\n",
      "iteration 2: x = [ 3.31352743 -0.62705486]\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "alpha_gd = 0.1\n",
    "alpha_nm = 1.0\n",
    "x0 = np.array([0.5, 0.5])\n",
    "df = lambda x: np.array([2*x[0] + x[1] - 6, x[0] + (1/4)*(x[1]**3) + 2*x[1] - 2])\n",
    "d2f = lambda x: np.array([[2, 1], [1, (3/4)*(x[1]**2) + 2]])\n",
    "\n",
    "print(\"Grandient descent\")\n",
    "gradient_descent(x0, df, alpha_gd, n)\n",
    "\n",
    "print(\"Newton method\")\n",
    "newton_method(x0, df, d2f, alpha_nm, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4\n",
    "(i)\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\min \\ \\frac{1}{2}\\| Ax - b \\|_2^2 \\\\\n",
    "    &  \\ \\text{s.t. } \\ x \\geq 0\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    & A'Ax - A'b - \\lambda = 0, \\\\\n",
    "    & \\lambda'x = 0, \\ x \\geq 0, \\ \\lambda \\geq 0\n",
    "\\end{align*}\n",
    "\n",
    "(ii)\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\min \\ \\sum_{j = 1}^n x_j \\log x_j\\\\\n",
    "    & \\text{s.t. } \\ \\sum_{j = 1}^n x_j = 1\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\log x_i - \\lambda_i + \\mu = 0 \\ \\ \\text{for} \\ \\ i = 1, \\cdots, n, \\\\\n",
    "    & \\sum_{j = 1}^n x_j  - 1 = 0, \\\\\n",
    "    & \\lambda_i x_i = 0, \\ x_i \\geq 0, \\ \\lambda_i \\geq 0 \\ \\ \\text{for} \\ \\ i = 1, \\cdots, n \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5\n",
    "\n",
    "\\begin{align*}\n",
    "    & \\min \\ x_2 \\\\\n",
    "    &  \\ \\ \\text{s.t. } \\ (x_1 + 1)^2 + x_2^2 \\leq 1 \\\\\n",
    "    &  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (x_1 - 1)^2 + x_2^2 \\leq 1\n",
    "\\end{align*}\n",
    "\n",
    "KKT条件は、\n",
    "\\begin{align*}\n",
    "    & 2\\lambda_1(x_1 + 1) + 2\\lambda_2(x_1 - 1) = 0, \\\\\n",
    "    & 1 + 2\\lambda_1x_2 + 2\\lambda_2x_2 = 0, \\\\\n",
    "    & \\lambda_1\\left\\{ (x_1 + 1)^2 + x_2^2 - 1 \\right\\} = 0, \\\\\n",
    "    & \\lambda_2\\left\\{ (x_1 - 1)^2 + x_2^2 - 1 \\right\\} = 0, \\\\\n",
    "    & \\lambda_1 \\geq 0, \\ \\lambda_2 \\geq 0\n",
    "\\end{align*}\n",
    "\n",
    "最適解は $(0, 0)$ だが、このとき制約式の勾配は両式ともに $(1, 0)'$ になり、KKT条件を満たす $\\lambda_1, \\ \\lambda_2$ は存在しない。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6\n",
    "\n",
    "目的関数を $x_l$ についてまとめると、定数 $C$ を用いて\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}x_l^2a_l'a_l + \\sum_{j \\neq i}x_lx_ja_l'a_j - b'x_la_l + \\gamma |x_l| + C  =\n",
    "        \\begin{cases}\n",
    "            \\frac{1}{2}x_l^2a_l'a_l + \\sum_{j \\neq i}x_lx_ja_j'a_l - b'x_la_l + \\gamma x_l + C \\ \\ \\text{if} \\ \\ x_l \\geq 0 \\\\\n",
    "            \\frac{1}{2}x_l^2a_l'a_l + \\sum_{j \\neq i}x_lx_ja_j'a_l - b'x_la_l - \\gamma x_l + C \\ \\ \\text{if} \\ \\ x_l \\leq 0\n",
    "        \\end{cases}\n",
    "$$\n",
    "これは、二次関数の場合分け問題に帰着するので、最小値をとる $x_l$ が不等式制約を満たすか場合分けすれば、\n",
    "$$\n",
    "x_l =\n",
    "    \\begin{cases}\n",
    "        \\frac{1}{\\| a_l \\|_2^2} \\left( \\left( b - \\sum_{j \\neq i}x_ja_j \\right)' a_l - \\gamma \\right) \\ \\ & \\text{if} \\ \\ \\left( b - \\sum_{j \\neq i}x_ja_j \\right)' a_l - \\gamma > 0 \\\\\n",
    "        0 & \\text{if} \\ \\ - \\gamma \\leq \\left( b - \\sum_{j \\neq i}x_ja_j \\right)' a_l \\leq \\gamma \\\\\n",
    "        \\frac{1}{\\| a_l \\|_2^2} \\left( \\left( b - \\sum_{j \\neq i}x_ja_j \\right)' a_l + \\gamma \\right)  \\ \\ & \\text{if} \\ \\ \\left( b - \\sum_{j \\neq i}x_ja_j \\right)' a_l + \\gamma <> 0\n",
    "    \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
