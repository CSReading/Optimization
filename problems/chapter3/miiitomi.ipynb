{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1\n",
    "次の関数の勾配とヘッセ行列を求めよ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i)\n",
    ">$$f(x) = 2 x_1^3 - x_1^2x_2 + 2x_2^2.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla f(x) = \\begin{bmatrix}\n",
    "                6 x_1^2 - 2x_1x_2\\\\\n",
    "                -x_1^2 + 4x_2\n",
    "              \\end{bmatrix},\\ \n",
    "\\nabla^2 f(x) = \\begin{bmatrix}\n",
    "                  12x_1 - 2x_2  &  -2x_1\\\\\n",
    "                  -2x_1  & 4\n",
    "                \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of function evaluations has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "# 最適解なし\n",
    "f = lambda x: 2*(x[0]**3) - (x[0]**2)*x[1] + 2*(x[1]**2)\n",
    "x0 = np.array([1.0, 1.0])\n",
    "res = opt.minimize(f, x0, method=\"nelder-mead\", options={\"disp\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 14\n",
      "         Function evaluations: 64\n",
      "         Gradient evaluations: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 8.47274610e-04, -7.46373373e-09])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# methodを指定しないと嘘解が求まっちゃう\n",
    "res = opt.minimize(f, x0, options={\"disp\": True})\n",
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii)\n",
    ">$$ f(x) = (x_1 - 3)^2 + x_1 x_2 + \\frac{1}{16}x_2^4 + (x_2 - 1)^2. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\nabla f(x) = \\begin{bmatrix}\n",
    "                    2x_1 + x_2 - 6 \\\\\n",
    "                    x_1 + \\frac{1}{4} x_2^3 + 2x_2 - 2\n",
    "                  \\end{bmatrix},\\ \n",
    "    \\nabla^2 f(x) = \\begin{bmatrix}\n",
    "                      2 & 1\\\\\n",
    "                      1 & \\frac{3}{4}x_2^2 + 2\n",
    "                    \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677505\n",
      "         Iterations: 46\n",
      "         Function evaluations: 88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.3128884 , -0.62579102])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: (x[0]-3)**2 + x[0]*x[1] + (1/16)*(x[1]**4) + (x[1]-1)**2\n",
    "x0 = np.array([1.0, 1.0])\n",
    "res = opt.minimize(f, x0, method=\"nelder-mead\", options={\"disp\": True})\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.677505\n",
      "         Iterations: 7\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.31290812, -0.6258167 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 勾配を指定して BFGS を使った方が収束が早い.\n",
    "def jac(x):\n",
    "    output = np.zeros(2)\n",
    "    output[0] = 2*x[0] + x[1] - 6\n",
    "    output[1] = x[0] + (1/4)*(x[1]**3) + 2*x[1] - 2\n",
    "    return output\n",
    "\n",
    "res = opt.minimize(f, x0, method=\"BFGS\", jac=jac, options={\"disp\": True})\n",
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii)\n",
    ">$$ f(x) = \\| Ax-b \\|_2^2 + \\gamma \\|x\\|_2^2. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\nabla f(x) = 2(A'A + \\gamma I)x - 2A'b,\\ \n",
    "    \\nabla^2 f(x) = 2(A'A + \\gamma I).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iv)\n",
    ">$$ f(x) = \\sum_{j=1}^n \\log\\left(1+\\exp(-x_j)\\right). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\nabla f(x) = \\begin{bmatrix}\n",
    "                    -\\frac{\\exp(-x_1)}{1 + \\exp(-x_1)} \\\\\n",
    "                    \\vdots \\\\\n",
    "                    -\\frac{\\exp(-x_n)}{1 + \\exp(-x_n)}\n",
    "                  \\end{bmatrix},\\ \n",
    "    \\nabla^2 f(x) = \\begin{bmatrix}\n",
    "                      \\frac{\\exp(-x_1)}{(1 + \\exp(-x_1))^2} & & O\\\\\n",
    "                      & \\ddots & \\\\\n",
    "                      O & & \\frac{\\exp(-x_n)}{(1 + \\exp(-x_n))^2}\n",
    "                    \\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(v)\n",
    ">$$ f(x) = \\log\\left( \\sum_{j=1}^n \\exp(x_j) \\right). $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\nabla f(x) = \\begin{bmatrix}\n",
    "                    \\frac{\\exp(x_1)}{\\sum_{j=1}^n \\exp(x_j)} \\\\\n",
    "                    \\vdots \\\\\n",
    "                    \\frac{\\exp(x_n)}{\\sum_{j=1}^n \\exp(x_j)}\n",
    "                  \\end{bmatrix},\\ \n",
    "    \\nabla^2 f(x) = (H_{ij})\\ \\mathrm{where}\\ \\ \n",
    "    H_{ij} = \\begin{cases}\n",
    "                \\frac{\\sum_{k\\ne i}\\exp(x_i + x_k)}{\\left(\\sum_{k=1}^n \\exp(x_k)\\right)^2} &\\ \\mathrm{if}\\ \\ i = j, \\\\\n",
    "                \\frac{-\\exp(x_i + x_j)}{\\left(\\sum_{k=1}^n \\exp(x_k)\\right)^2} &\\ \\mathrm{if}\\ \\ i \\ne j.\n",
    "             \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2\n",
    ">正定値対称行列 $A = (A_{ij}) \\in \\mathbb{R}^{n\\times n}$, ベクトル $b \\in \\mathbb{R}^n$ に対し, 連立1次方程式\n",
    ">$$ Ax = b \\tag{3.32} $$\n",
    ">の解と無制約最適化問題\n",
    ">$$ \\min f(x) = \\frac{1}{2}x'Ax - b'x  \\tag{3.33} $$\n",
    ">の解が一致することを示せ. また, $\\nabla^2 f(x) = A$ を示せ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$A$ の対称性より, $f(x)$ の勾配およびヘッセ行列は,\n",
    "$$\n",
    "    \\nabla f(x) = \\frac{1}{2}(A + A')x - b = Ax - b,\\ \\nabla^2 f(x) = A.\n",
    "$$\n",
    "また $A$ は正定値行列なので, $f$ は狭義凸関数.\n",
    "したがって $x^*$ が (3.33) の大域最適解であることの必要十分条件は,\n",
    "$$\n",
    "    \\nabla f(x^*) = A x^* - b = 0\n",
    "$$\n",
    "である."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4\n",
    ">次の制約付き最適化問題に対するKKT条件を書け."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i)\n",
    ">$$\n",
    ">\\begin{align*}\n",
    ">   \\min \\ \\ &\\frac{1}{2}\\|Ax - b\\|_2^2\\\\\n",
    ">   \\mathrm{s.t.}\\ \\ &x \\ge 0.\n",
    ">\\end{align*}\n",
    ">$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "        &A'A -A'b - \\lambda = 0\\\\\n",
    "        &\\lambda_j x_j = 0, \\ \\lambda_j \\ge 0, \\ x_j \\ge 0 \\ \\ \\mathrm{for}\\ \\ j = 1,\\dots,n.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii)\n",
    ">$$\n",
    ">\\begin{align*}\n",
    ">   \\min \\ \\ &\\sum_{j=1}^nx_j\\log x_j\\\\\n",
    ">   \\mathrm{s.t.}\\ \\ &\\sum_{j=1}^n x_j = 1,\\\\\n",
    ">                    &x \\ge 0.\n",
    ">\\end{align*}\n",
    ">$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "    &\\log x_j + 1 + \\mu - \\lambda_j = 0 \\ \\ \\mathrm{for}\\ \\ j = 1,\\dots,n,\\\\\n",
    "    &\\sum_{j=1}^n x_j = 1,\\\\\n",
    "    &\\lambda_j x_j = 0,\\ \\lambda_j \\ge 0,\\ x_j \\ge 0 \\ \\ \\mathrm{for}\\ \\ j = 1,\\dots,n.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6\n",
    ">$\\ell_1$ ノルム正則化付き最小2乗法\n",
    ">$$ \\min_{x}\\ \\  \\frac{1}{2}\\left\\| \\sum_{j=1}^n x_j a_j - b \\right\\|_2^2 + \\gamma \\sum_{j=1}^n |x_j| $$\n",
    ">に対する座標降下法の更新式を求めよ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目的関数を $f(x)$ とおき, これを $x_l$ について整理すると,\n",
    "$$\n",
    "\\begin{align*}\n",
    "    f(x) &= \\frac{1}{2}\\left\\| x_l a_l + \\sum_{j\\ne l}x_j a_j - b \\right\\|_2^2 + \\gamma |x_l| + \\gamma \\sum_{j\\ne l}|x_j| \\\\\n",
    "    &= \\frac{1}{2}\\left(\\|a_l\\|_2^2 x_l^2 + 2 \\left(\\sum_{j\\ne l}x_j a_j - b\\right)'a_l x_l \\right) + \\gamma |x_l| + C\\\\\n",
    "    &= \\begin{cases}\n",
    "            \\frac{1}{2}\\left(\\|a_l\\|_2^2 x_l^2 + 2 \\left(\\sum_{j\\ne l}x_j a_j - b\\right)'a_l x_l \\right) + \\gamma x_l + C & \\ \\mathrm{if}\\ \\ x_l \\ge 0\\\\\n",
    "            \\frac{1}{2}\\left(\\|a_l\\|_2^2 x_l^2 + 2 \\left(\\sum_{j\\ne l}x_j a_j - b\\right)'a_l x_l \\right) - \\gamma x_l + C & \\ \\mathrm{if}\\ \\ x_l < 0\n",
    "       \\end{cases}\n",
    "\\end{align*}\n",
    "$$\n",
    "となる（ただし $C$ は $x_l$ と無関係な項）.\n",
    "よって $x_{-l}$ を固定したときに $f(x_l, x_{-l})$ を最小化する点 $x_l$ の候補は, \n",
    "- $p = \\frac{1}{\\|a_l\\|_2^2} \\left( \\left( b - \\sum_{j \\ne l}a_jx_j \\right)'a_l - \\gamma \\right) $ $ \\ \\cdots \\ $ (  $x_l > 0$ 領域の放物線の頂点)\n",
    "- $q = 0$ $ \\ \\cdots \\ $ ( 領域の境界 )\n",
    "- $r = \\frac{1}{\\|a_l\\|_2^2} \\left( \\left( b - \\sum_{j \\ne l}a_jx_j \\right)'a_l + \\gamma \\right) $ $ \\ \\cdots \\ $ (  $x_l < 0$ 領域の放物線の頂点)\n",
    "\n",
    "に絞られる.\n",
    "\n",
    "(Case 1): $\\left( b - \\sum_{j \\ne l}a_jx_j \\right)'a_l > \\gamma$ の場合.\n",
    "- $0 = q < p < r$ となるので, $f$ が最小になるのは $x_l = p$ のとき.\n",
    "\n",
    "(Case 2): $\\left( b - \\sum_{j \\ne l}a_jx_j \\right)'a_l < -\\gamma$ の場合.\n",
    "- $p < r < q = 0$ となるので, $f$ が最小になるのは $x_l = r$ のとき.\n",
    "\n",
    "(Case 3): $-\\gamma \\le \\left( b - \\sum_{j \\ne l}a_jx_j \\right)'a_l \\le \\gamma$ の場合.\n",
    "- $p < q = 0 < r$ となるので, $f$ が最小になるのは $x_l = q$ のとき.\n",
    "\n",
    "よって座標降下法の更新式は, \n",
    "$$\n",
    "    x_l \\leftarrow \\frac{1}{\\|a_l\\|_2^2} \\psi\\left( \\left( b - \\sum_{j \\ne l}a_jx_j \\right)'a_l \\right)\n",
    "$$\n",
    "と書ける, ただし $\\psi$ は\n",
    "$$\n",
    "    \\psi(s) = \\begin{cases}\n",
    "                  s - \\gamma & \\ \\ \\mathrm{if}\\ \\ s > \\gamma,\\\\\n",
    "                  0 & \\ \\ \\mathrm{if}\\ \\ |s| \\le \\gamma,\\\\\n",
    "                  s + \\gamma & \\ \\ \\mathrm{if}\\ \\ s < -\\gamma\n",
    "              \\end{cases}\n",
    "$$\n",
    "なる関数."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
